{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXrXKAgTp9pIL3EggqnJ5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammadharis356/-PIAIC-AgenticAi-Robotics/blob/main/Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S27oJMOIKD83",
        "outputId": "57f40997-bba1-45e7-a89b-31464adbbbc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-opentutorial\n",
            "  Downloading langchain_opentutorial-0.0.6-py3-none-any.whl.metadata (686 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from langchain-opentutorial) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->langchain-opentutorial) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->langchain-opentutorial) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->langchain-opentutorial) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->langchain-opentutorial) (2024.12.14)\n",
            "Downloading langchain_opentutorial-0.0.6-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: langchain-opentutorial\n",
            "Successfully installed langchain-opentutorial-0.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain_google_genai\",\n",
        "        \"google-generativeai\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ],
      "metadata": {
        "id": "gNMEige8ddZw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "google_api_key=userdata.get('GOOGLE_API_KEY')\n",
        "langchain_api_key=userdata.get('langchain_api_key')"
      ],
      "metadata": {
        "id": "ww8tnumFLUZE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Retrieve API keys (replace with your actual key retrieval method)\n",
        "from google.colab import userdata\n",
        "google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "langchain_api_key = userdata.get('langchain_api_key')\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Video-Q&A-LLM-Gemini\""
      ],
      "metadata": {
        "id": "3OYHMZYad7Y5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/Unveiling the Future_ Exciting Product Announcement!-VEED.mp4\""
      ],
      "metadata": {
        "id": "Ba2ACXtmfpC5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=google_api_key)\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
        "print(\"Uploading files...\")\n",
        "\n",
        "# Upload the file and return the file object\n",
        "video_file = genai.upload_file(path=video_path)\n",
        "\n",
        "print(f\"Upload complete: {video_file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "s6ByRjA1fyGd",
        "outputId": "79651c76-8c54-4d42-d28e-97dd19cc2679"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading files...\n",
            "Upload complete: https://generativelanguage.googleapis.com/v1beta/files/zt4l0z8zcc3k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Videos need to be processed before you can use them.\n",
        "while video_file.state.name == \"PROCESSING\":\n",
        "    print(\"Please wait while the video upload and preprocessing are completed...\")\n",
        "    time.sleep(5)\n",
        "    video_file = genai.get_file(video_file.name)\n",
        "\n",
        "# Raise an exception if the processing fails\n",
        "if video_file.state.name == \"FAILED\":\n",
        "    raise ValueError(video_file.state.name)\n",
        "\n",
        "# Print completion message\n",
        "print(\n",
        "    f\"\\nVideo processing is complete!\\nYou can now start the conversation: {video_file.uri}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "j80r5qzygndB",
        "outputId": "6f8ed0c1-9816-4d05-fe36-2a6cb2af44a9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please wait while the video upload and preprocessing are completed...\n",
            "\n",
            "Video processing is complete!\n",
            "You can now start the conversation: https://generativelanguage.googleapis.com/v1beta/files/zt4l0z8zcc3k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt message\n",
        "prompt = \"Describe this video clip\"\n",
        "\n",
        "# Set model to Gemini 1.5 Flash\n",
        "#model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash\")\n",
        "\n",
        "# request stream response to LLM\n",
        "response = model.generate_content(\n",
        "    [prompt, video_file], stream=True\n",
        ")\n",
        "\n",
        "# print stream response\n",
        "for chunk in response:\n",
        "    print(chunk.text, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "UxoTy0ZXg8zv",
        "outputId": "77badde1-e280-4996-c760-a708109a4425"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! The video clip presents a product advertisement for a smart home hub. It starts by displaying a dark round smart speaker. A man is then shown holding and using a tablet. Next is a view of a finger using a phone app with a multicolored dial, which changes the lighting. A man then uses a phone, presumably in the dark, to control devices. The following scene shows a graphic of a house opening a garage door and a car entering, all presumably controlled by the hub. Then, we see a woman choosing shoes, followed by a man using a phone to control lighting within the home."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Initialize the Gemini model with the specified version\n",
        "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp')\n",
        "\n",
        "# Create a message to send to the model and attach the video file as media input\n",
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\"type\": \"text\", \"text\": \"Please analyze the content of this video.\"},\n",
        "        {\n",
        "            \"type\": \"media\",\n",
        "            \"mime_type\": video_file.mime_type,\n",
        "            \"file_uri\": video_file.uri,\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Stream the response and process each chunk\n",
        "for chunk in llm.stream([message]):\n",
        "    print(chunk.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phDsTbL5hey4",
        "outputId": "4596cdc0-2f3b-4b74-bac5-b0a1d06689f1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly\n",
            "! Here is an analysis of the video:\n",
            "\n",
            "**Overall Theme:**\n",
            "\n",
            "The\n",
            " video is an advertisement for a new smart home device called the \"Smart Home Hub\n",
            "\". It highlights the device's capabilities in simplifying home automation.\n",
            "\n",
            "**Visual Elements:**\n",
            "\n",
            "*   The video starts with a shot of a black mesh-\n",
            "covered speaker, likely the hub itself. There is a plant in the background, creating a domestic, modern feel.\n",
            "*   It then shows a person using\n",
            " a tablet, transitioning to a close-up of a finger using a colorful color-wheel interface on a phone or tablet. This indicates a visual, touch-based control element for the hub.\n",
            "*   There are some shots of a\n",
            " person using the hub for hands-free control, likely voice activated. \n",
            "*   The video then uses animation to portray the hub opening a garage door and a car being driven in. This is meant to show the hub's capabilities\n",
            ".\n",
            "*   The video then transitions to a woman looking at a shoe in a shop. This is meant to demonstrate the hub's ability to integrate with a person's everyday routine.\n",
            "*   Finally, the video shows a person using an app on their smartphone, controlling the hub's features.\n",
            "**Audio Elements:**\n",
            "\n",
            "*   The video has a narrator who speaks in a calm, assuring tone.\n",
            "*   The narrator uses phrases such as \"latest innovation,\" \"simplifies your daily routine,\" \"enhances your lifestyle,\" and \"all-in-one solution,\" highlighting the device's benefits.\n",
            "*   The narrator explains that the device offers voice control, seamless integration with favorite devices, and energy-saving features.\n",
            "*   The audio includes a brief sound effect of a door opening as the animated garage door opens.\n",
            "\n",
            "**Key Features Highlighted:**\n",
            "\n",
            "*   **Convenience:** The device is presented as\n",
            " a tool to make daily life easier, particularly home management.\n",
            "*   **Home Automation:** The device appears to centralize control of various home systems like lights, thermostat, and security.\n",
            "*   **Voice Control:** The device is voice-activated, enabling hands-free control.\n",
            "*   **Device Integration\n",
            ":** The hub seamlessly integrates with other devices.\n",
            "*   **Energy Saving:** The device includes energy-saving features.\n",
            "*   **Learning Capabilities:** The device learns user preferences over time.\n",
            "\n",
            "**Target Audience:**\n",
            "\n",
            "The video likely targets tech-savvy individuals interested in smart home solutions and who want an easy way\n",
            " to control the various elements in their home.\n",
            "\n",
            "**Overall Message:**\n",
            "\n",
            "The video emphasizes that the Smart Home Hub is a cutting-edge device that simplifies home automation, making life more convenient and efficient. It is presented as an all-in-one solution that learns user preferences.\n",
            "\n",
            "Let me know if you have\n",
            " any further questions!\n"
          ]
        }
      ]
    }
  ]
}